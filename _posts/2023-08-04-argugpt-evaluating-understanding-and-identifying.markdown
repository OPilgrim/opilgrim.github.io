---
layout: post
title:  ArguGPT: evaluating, understanding and identifying argumentative essays generated by GPT models
date:   2023-08-04 10:24:35 +0300
tags:   Translation
lang: zh
---




### Abstract

人工智能模型生成的内容对世界各地的教育工作者提出了相当大的挑战。当学生提交AI生成内容(AIGC)作为自己的工作时，教师将需要能够用肉眼或借助一些工具检测此类文本。对AIGC的词法、句法和文体特征的了解也越来越迫切。

为解决英语语言教学背景下的这些挑战，本文首先提出ArguGPT，一个精心平衡的语料库，由7个GPT模型根据三个来源的文章提示生成4,038篇议论文:(1)课堂或家庭作业，(2)托福写作任务和(3)GRE写作任务。这些机器生成的文本与数量大致相等的人工撰写的文章相匹配，在文章提示中得到低、中、高的分数。

然后，我们聘请英语教师来区分机器论文和人类论文。结果显示，当教师第一次接触到机器生成的论文时，他们识别它们的准确率只有61%。但经过一轮最低限度的自我训练后，这个数字上升到67%。对机器和人工作文进行了语言分析，结果表明，机器生成的句子具有更复杂的句法结构，而人工作文往往在词汇上更复杂。最后，我们测试了现有的AIGC检测器，并使用svm和RoBERTa模型构建了我们自己的检测器。实验结果表明，使用ArguGPT训练集对RoBERTa进行微调后，在文章级别和句子级别的分类中都可以达到90%以上的准确率。

据我们所知，这是第一次对生成式大型语言模型产生的议论文进行全面分析。本文工作表明，教育工作者需要了解AIGC，介绍了人工智能生成议论文的特点，并表明从同一领域检测AIGC似乎是基于机器学习分类器的一项简单任务。机器撰写的论文和我们的模型将在https://github.com/huhailinguist/ArguGPT上公开。



### 1 Introduction

三个问题：

1. 人类评价者(语言教师)能区分由GPT模型生成的英语议论文和人类语言学习者写的**英语议论文**吗?
2. 与语言学习者的作文相比，机器生成的作文有什么语言特征?
3. 机器学习分类器能区分机器生成的作文和人工写作的作文吗?

为回答这些问题，本文首先使用GPT家族的七个模型(GPT2-XL、GPT3的变体和ChatGPT)收集了4038篇机器生成的论文，以响应来自多个级别的英语熟练程度和写作任务(课堂写作练习、托福和GRE)的632个提示。然后，将这些文章与4,115篇人工撰写的低、中、高水平的文章进行配对，形成ArguGPT语料库。该文对43名中国英语新手和有经验的英语教师进行了人工评价测试，以识别一篇文章是机器写的还是人写的。随后，该文利用Lu(2010, 2012)的工具和方法，对人工作文和机器生成作文的31个句法和词汇语言学指标进行了比较，旨在揭示gpt生成作文的文本特征。最后，在ArguGPT语料库的开发集和测试集上对现有的AIGC检测器GPTZero4以及基于SVM和RoBERTa的AIGC检测器进行测试。

我们的主要发现和贡献是:

- 本文为NLP和ESOL研究人员提供了第一个大规模、平衡的ai生成的议论文语料库。
- 英语教师很难识别gpt生成的文本。英语教师在第一轮中区分人工和gpt撰写的文章的准确率为61.6%，在经过一些最小的训练后，准确率上升到67.7%，比Clark等人之前的报告(2021)高出大约10分，这可能是由于教师熟悉学生写的文本。有趣的是，它们更擅长检测低级别的人工论文，而不是高级的机器论文。
- 在句法和词汇的复杂性方面，我们发现，最好的GPT模型生成的句子在句法上比人类(英语语言学习者)更复杂，但GPT撰写的文章往往在词汇上没有那么复杂。
- 本文发现，机器学习分类器可以很容易地区分机器生成的作文和人工撰写的作文，通常具有非常高的准确性，这与Guo等人(2023)的结果类似。GPTZero在文章级别和句子级别上都有90%以上的准确率。表现最好的RoBERTa-large模型在ArguGPT上进行了微调，在测试集上的文章水平上达到了99%的准确率，在句子水平上达到了93%。
- 机器撰写的文章将在https://github.com/huhailinguist/ arggpt上发布。我们的ArguGPT检测器和相关模型的演示可以在https://huggingface.co/spaces/SJTU-CL/argugpt-detector上找到。





### 4  Linguistic analysis

在本节中，我们将比较机器作文和人工作文的语言特征。将文章按作者分组:1)低水平人类，2)中等水平人类，3)高水平人类，4)gpt2-xl, 5) text-babbage-001, 6) text- curcie -001, 7) text-davinci-001, 8) text-davinci-002, 9) text-davinci-003，和10)gpt-3.5-turbo。

首先给出了人工作文和机器作文的描述性统计。然后，我们使用第二语言(L2)写作研究中既定的措施和工具来分析人类和机器书面文本的句法复杂性和词汇丰富性(Lu, 2012,2010)。

#### 4.1 Methods

