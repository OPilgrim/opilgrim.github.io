---
layout: post
title:  Counterfactual Debiasing for Fact Verification
date:   2023-07-19 11:01:35 +0300
tags:   Style
lang: zh
---
(转载) 本文介绍我们团队发表在**ACL2023上的基于反事实推理的虚假信息检测鲁棒性增强框架的工作: Counterfactual Debiasing for Fact Verification**。

![]({{site.baseurl}}/counterfactual_debiasing_for_fact_verification/0.png)

### 1 引言

随着信息数量急剧增长，未经证实的言论在网络上变得普遍，给公共安全（如公共卫生、政治和经济等领域）带来威胁。因此，事实验证任务受到研究者的关注。现有的事实验证数据集在人工标注时不可避免地引入偏置信息。例如，FEVER数据集中的否定词（如"not"和"never"）与"REFUTES"标签高度相关。这种偏置信息可能误导模型，使其关注言论中部分特征与标签的虚假相关性，而忽略真实的证据。因此，尽管模型在有偏数据集上表现良好，但在真实无偏数据集上的性能显著下降，并容易受到对抗性样本的攻击。

为了解决上述问题，之前的研究已经提出了几种增强鲁棒性的方法，大致可分为两类。第一类是基于数据增强的方法，利用启发式的设计方案，如词语交换和词组替换，生成额外的训练数据。然而，这些方法严重依赖于增强数据的质量，并且由于其固定的增强规则，难以适用于复杂的情况，比如多跳证据推理场景。

第二类方法旨在减少具有偏置的样本对模型训练损失函数的贡献。关键问题转变为如何识别存在偏置的样本。具体而言，Schuster等人将与含有高度虚假相关的n-gram标签的样本视为具有偏置的样本，并通过降低它们的权重来减少偏置。Mahabadi等人假设仅含言论而不含证据的模型正确分类的实例具有偏置。尽管这两种方法都取得了不错的效果，但前者缺乏对不同类型偏置的适用性，因为它们只关注n-gram信息；后者则依赖于主模型和仅含言论输入模型对具有偏置样本的预测相似的假设，然而这一假设并不总是成立。此外，训练期间仅含言论输入模型的不准确预测可能错误地导致无偏置样本的权重下降。

### 2 模型方法

本节中，我们将详细介绍提出的鲁棒性增强框架CLEVER，其整体结构设计如图1所示。

![]({{ site.baseurl }}/counterfactual_debiasing_for_fact_verification/1.png)
*图1 提出的框架CLEVER*

第一步是构建一个与事实验证任务标准设置不同的反事实场景。在我们的任务中（如图1上半部分所示），标准设置是输出受到因果图$\mathcal{G}_o$中同时包含言论和对应证据的影响。我们将言论$c$和证据${e_1, e_2, \ldots, e_n}$作为输入来模拟这种情况。表示为：
$$
O_{c,e} = f_s(c, e_1, e_2, ..., e_n)
$$
接下来的关键问题是如何设计一个反事实场景来去除偏置。从因果关系的角度来看，如果我们希望评估一个变量对结果的影响，我们可以对该变量进行干预，同时保持其他变量不变。针对我们的目标，即获得受言论和证据共同影响的无偏预测结果，我们采取的干预方式是使言论-证据融合信息对事实验证模型不可见。换句话说，如图1下半部分所示，我们通过对原始因果图$\mathcal{G}_o$进行干预，构建一个反事实场景的因果图$\mathcal{G}_i$，其中从言论-证据融合信息节点到预测结果节点的边被切断。我们独立地训练另一个事实验证模型$f_{b}$，以模拟言论-证据信息不可见的情况，要求该模型仅基于言论生成预测结果$\mathbf{O}_{c} \in \mathbb{R}^L$:
$$
O_c = f_b(c)
$$
第二步是比较事实性场景和反事实场景中的输出。仅输入言论的模型的输出$\mathbf{O}_{c}$可认为存在严重的偏置，因为它只是简单地拟合言论中的词语和标签之间的虚假相关性。为了减少这种偏置，受潜在结果模型（Potential Outcomes Model）的启发，我们从$\mathbf{O}_{c,e}$中减去$\mathbf{O}_{c}$，得到去除偏置的输出$\mathbf{O}_{u}$，
$$
O_u = O_{c, e} - O_c
$$
**训练和推断** 在训练阶段，由于偏置信息主要存在于言论中，我们希望利用只有言论输入的模型来捕获这种偏置。为了达到这个目标，我们通过对$O_c$施加分类损失函数来促进仅含言论的模型输出有偏的标签分布$O_c$。同时，$O_{c,e}$也被施加同样的损失函数，独立地训练言论-证据对作为输入的模型，以捕捉言论与证据的交互信息。我们将两个损失函数直接求和得到最终的损失函数，
$$
L = L_{cl}f(O_c) + L_{cl}f(O_{c,e})
$$
在推理阶段，由于经过训练后，反事实场景的输出$O_c$存在偏置，我们通过从事实性场景的输出$O_{c,e}$中减去它来缓解偏置。

**讨论与分析** 总体而言，我们提出了CLEVER框架，其包括一个言论-证据交互模型和一个仅含言论输入的模型，用于捕捉交互信息和有偏信息。与当前主流的基于权重调整的方法相比，我们的去偏框架有几个关键差异。首先，我们不依赖于两个独立模型输出相似的假设，这是基于权重调整的方法的前提。其次，我们没有使用仅含言论输入模型的不准确输出来调整言论-证据交互模型的训练损失。相反，我们独立地训练言论-证据交互模型和仅含言论输入的模型，并基于潜在结果模型提出了一种简单而有效的方案，在推理阶段获得去偏置的结果，从而增强模型的鲁棒性。

### 3 实验结果

**3.1 数据集**

我们使用了三类数据集来全面评估我们提出的方法的有效性。

**单跳数据集** 我们使用一个有偏的训练集 FEVER-Train来训练模型，并使用一个无偏的数据集 FEVER-Symmetric 和一个对抗样本数据集 FEVER-Adversarial来测试模型。这些数据集的设置与现有工作保持一致。此外，我们还引入了 FEVER-Dev 的一个新的无偏子集FEVER-Hard。出于阐述简洁性的考虑，我们在以下实验分析中描述数据集时省略了“FEVER”前缀，因为所有无偏和对抗样本数据集均从原始 FEVER 数据集派生出来。其中所有样本均无法被只输入言论的模型进行正确分类。也就是说，FEVER-Hard 中的样本是无偏的，因为言论中没有误导模型的偏置信息。因此，我们采用它来评估模型不依赖于言论偏置的表现。

**多跳数据集** 现有的工作仅关注简单的单跳推理场景，当前训练集和测试集中的每个样本仅涉及一条证据。然而，在实际应用中，一些复杂的场景需要模型具备多跳推理能力。因此，为了进一步验证多跳场景下的模型的去偏性能，我们在数据集 Train 和 Dev 上增加了包含多条证据的样本，构建了两个多跳数据集 Train-MH 和 Dev-MH。然后，我们将不能使用只输入言论的模型进行正确预测的多跳实例加入 Hard 中，形成一个新的多跳测试集 Hard-MH。

**多域数据集** 此外，我们使用一个名为 MultiFC 的数据集来评估不同去偏方法在多域情况下的性能。MultiFC 包含来自网站上各个领域的言论，例如政治、体育和娱乐。单跳和多跳设置下的 FEVER 数据集中的言论是基于维基百科人工构建的，通常仅限于事实性常识信息，例如名人的国籍。因此，我们引入了上述多域数据集 MultiFC，来验证所提出的方法是否能够应对具有不同形式和领域风格的言论。为了保持与测试集类似的数据分布（测试集只包含“SUPPORTS”和“REFUTES”样本），我们在训练所有模型时都不使用“NOT ENOUGH INFO”样本。我们按照已有工作的设置，使用标签分类准确性作为度量标准。

**3.2基线方法**

我们将我们提出的方法与现有两个流派中的基线方法进行比较：

**基于数据增强的方法:**

- EDA：他们通过交换单词和替换同义词的方式生成新的训练样本。

- CrossAug：他们设计了一个交叉对比策略来增强数据，对原始的正确言论修改局部关键信息，使其标签变为虚假。然后修改证据的相应部分与这些虚假言论保持语义一致，构成新的言论-证据对。

**基于权重调整的方法:**

- ReW：他们降低含有与标签高度相关的n-gram的样本的权重。

- PoE：他们降低了从仅含言论输入的模型预测正确的样本权重。

- MoCaD：他们提出了一种校准方法来调整从仅含言论输入的模型中不准确的预测分布。具体来说，他们使用了两个校准器（即温度缩放器和狄利克雷校准器）。我们采用这两个方法进一步优化了PoE模型，构建了两个PoE的模型变体，即PoE-TempS和PoR-Dirichlet。

**3.3 性能对比与分析**

图2展示了本章提出的CLEVER框架和几个基线方法的综合性能。可以看到，CLEVER在所有数据集上都显著优于来自现有不同流派的方法。接下来，我们阐述从结果中得到的进一步的分析：

首先，与以前的方法相比，CLEVER的性能提升幅度在所有数据集上都十分显著且稳定。从表格中可以观察到每个数据集上的性能处于第二位的方法都不同，而CLEVER在所有数据集上均取得最佳性能。更具体地说，与没有施加任何去偏方法的vanilla BERT模型（即BERT-base）相比，CLEVER在两个无偏数据集Symmetric和Hard上分别提高了17.55％和15.53％。此外，大多数基线方法，尤其是CrossAug，在Adversarial数据集上表现相对较差，因为去偏方法通常专门设计用于避免学习言论中的偏置，而并没有明确考虑对抗攻击样本的影响。相比之下，我们提出的方法仍然在这一数据集上取得了较大的性能提升（比BERT-base提高了约10％的性能），这证明了我们的方法具有同时处理对抗性和偏置性数据的泛化能力。这可能是因为我们的方法利用了一个仅包含言论的模型来自适应地捕捉模型容易陷入的偏置，而不是基于现有方法中的偏置词语的统计特征或依赖于偏置模型的不准确输出。

其次，EDA和ReW方法的表现相较于其他方法差距较大。这主要是因为它们捕捉偏置的方式不同。EDA和ReW都考虑在特定的单词或短语级别上的偏置。EDA用同义词替换一些特定的单词，而ReW预定义了经常与特定标签共同出现的有偏见的n-gram，这种方式可能缺乏灵活性，因为很难包含所有可能的偏置组合。相比之下，包括我们的方法在内的其余方法都训练了模型自动增强样本和捕捉偏置信息，这具有更好的泛化能力，可以学习不同模式的偏置。

![]({{ site.baseurl }}/counterfactual_debiasing_for_fact_verification/2.png)
*图2 不同方法之间的性能比较*

**3.4 多跳数据集上的性能**

现有方法只利用具有单条证据的样本来评估去偏的性能，但我们认为应该考虑更复杂的推理情况，因为在现实场景中，一条言论可能需要通过多条证据来验证。因此，我们进一步在多跳推理场景下验证提出的方法的性能，数据集包括带偏置的验证集Dev-MH和无偏置的测试集Hard-MH，其中的样本都是具有多条证据的样本。类似于单跳场景中的Hard数据集，Hard-MH也包含了所有仅基于言论产生错误预测的样本。由于基于数据增强的方法难以适配这种复杂的情况，我们将CLEVER与基于权重调整的流派中的基线进行比较。

如图3的右侧所示，在Hard-MH数据集上，CLEVER方法相叫于性能排在第二名的基线PoE-Dirichlet，预测准确率提升约7%，证明了其在复杂数据场景中的有效性。

![]({{ site.baseurl }}/counterfactual_debiasing_for_fact_verification/3.png)
*图3 多跳与多域数据集上的性能比较*

**3.5 多域数据集上的性能**

我们进一步在多域数据集 MultiFC 上验证了我们提出的CLEVER方法的去偏性能，该数据集包含从多个网站收集的大量言论。为适配我们模型的输出，我们将“真实的”、“大部分真实的”和“一半真实的”这三类标签合并为一类，将“完全虚假的”、“假的”和“大部分是假的”合并为一类。我们在 MultiFC 的训练集上训练模型，并在 MultiFC 的无偏子集Hard-MultiFC上获得性能，Hard子集的构建方式和之前两个场景内的一致。如图 3的左侧部分所示，实验结果证明了我们的方法在真实多领域场景的数据集上的有效性。此外，值得注意的是，在图2中的人工撰写言论的数据集上，BERT-base 和去偏方法之间的性能差距要比在真实场景数据集 MultiFC 上的性能差距大得多。导致这一现象的原因可能是现实场景中的偏置信息比手工制作的数据集中的偏置更为严重，后者只涉及文本偏见，而真实网站中的言论除了文本偏见外，还涉及实体偏见。实体可能指向某一名人，例如唐纳德·特朗普，通常与虚假言论呈现出有高度偏置的相关性，导致模型将所有含有特朗普实体的样本分类为虚假言论，这就是实体偏见。因此，研究去偏方法来缓解偏置对事实验证模型的负面影响是非常重要且有实际价值的。

### 4 总结

本文提出了一种新颖的基于反事实推理的CLEVER框架来缓解事实验证模型中的偏置，提高模型的鲁棒性。现存工作主要分为基于数据增强和基于权重调整的两个流派。与它们不同的是，CLEVER无需数据增强，同时也避免在训练阶段利用不准确输出调整权重，而是在推理阶段去除偏置信息。在CLEVER中，言论-证据融合模型和只含有言论输入的模型是分别独立训练的，旨在捕捉相应的交互信息和偏置信息。在推理阶段，基于因果推理领域的潜在结果模型，我们提出了一种简单且有效的计算方式来降低偏置信息对模型带来的影响。最后，我们做了全面的定量和定性实验，证明了CLEVER的有效性。
