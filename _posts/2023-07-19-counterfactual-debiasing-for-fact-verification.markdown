---
layout: post
title:  Counterfactual Debiasing for Fact Verification
date:   2023-07-19 12:00:00 +0300
image:  02.jpg
tags:   Style
---
(转载) 本文介绍我们团队发表在**ACL2023上的基于反事实推理的虚假信息检测鲁棒性增强框架的工作: Counterfactual Debiasing for Fact Verification**。

## 1 引言

随着信息数量急剧增长，未经证实的言论在网络上变得普遍，给公共安全（如公共卫生、政治和经济等领域）带来威胁。因此，事实验证任务受到研究者的关注。现有的事实验证数据集在人工标注时不可避免地引入偏置信息。例如，FEVER数据集中的否定词（如"not"和"never"）与"REFUTES"标签高度相关。这种偏置信息可能误导模型，使其关注言论中部分特征与标签的虚假相关性，而忽略真实的证据。因此，尽管模型在有偏数据集上表现良好，但在真实无偏数据集上的性能显著下降，并容易受到对抗性样本的攻击。

为了解决上述问题，之前的研究已经提出了几种增强鲁棒性的方法，大致可分为两类。第一类是基于数据增强的方法，利用启发式的设计方案，如词语交换和词组替换，生成额外的训练数据。然而，这些方法严重依赖于增强数据的质量，并且由于其固定的增强规则，难以适用于复杂的情况，比如多跳证据推理场景。

第二类方法旨在减少具有偏置的样本对模型训练损失函数的贡献。关键问题转变为如何识别存在偏置的样本。具体而言，Schuster等人将与含有高度虚假相关的n-gram标签的样本视为具有偏置的样本，并通过降低它们的权重来减少偏置。Mahabadi等人假设仅含言论而不含证据的模型正确分类的实例具有偏置。尽管这两种方法都取得了不错的效果，但前者缺乏对不同类型偏置的适用性，因为它们只关注n-gram信息；后者则依赖于主模型和仅含言论输入模型对具有偏置样本的预测相似的假设，然而这一假设并不总是成立。此外，训练期间仅含言论输入模型的不准确预测可能错误地导致无偏置样本的权重下降。

## 2 模型方法

本节中，我们将详细介绍提出的鲁棒性增强框架CLEVER，其整体结构设计如图1所示。

![图2 提出的框架CLEVER]({{ site.baseurl }}/images/11.jpg)
*图2 提出的框架CLEVER*

第一步是构建一个与事实验证任务标准设置不同的反事实场景。在我们的任务中（如图1上半部分所示），标准设置是输出受到因果图$\mathcal{G}_o$中同时包含言论和对应证据的影响。我们将言论$c$和证据${e_1, e_2, \ldots, e_n}$作为输入来模拟这种情况。表示为：
